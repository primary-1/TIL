사이트 신뢰성 엔지니어링 Site_Reliabillity_Engineering<br>
챕터 22. 연속적 장애
==========
연속적 장애
-----------------
    정상적인 거서럼 보여지는 응답 때문에 시간이 지나면서 장애가 가중되는 현상
>ex) 서비스의 단일 복제본에서 과부하 때문에 장애가 발생하면 나머지도 도미노처럼 장애가 발생함.

### 연속적 장애의 원인과 그 대책
    사전에 고려를 한 시스템 디자인은 연속적 장애를 유발할 수 있는 몇 가지 상황을 제대로 처리할 수 있어야 한다.

### 셰익스 피어 예제 서비스에서 벌어질 수 있는 일
<img src='https://landing.google.com/sre/book/images/srle-2202.jpg'>
```이렇게 된다면 A에 1000 이라는 데이터의 량을 감당해야한다.
결국 지연응답 혹은 오작동이 발생하여 A가 다운이 된다면

나머지 응답 또한 그대로 B에게 가 결국엔 전체 시스템에 도미노 처럼 영향이 간다.
```

## 자원의 부족
지연 응답, 에러율 증가, 혹은 낮은 품질 야기할 수 있음

### CPU 자원이 부족한 경우
    주로 모든 처리가 늦어져 부차적(副次的) 현상 발생

- 처리 요청 수 증가
    > 메모리 활성 스레드 수 , 파일 서술자, 백엔드 자원등 모든 영향에 끼침

- 비정상적으로 자라는 큐의 크기
    > 모든 요청을 안정적으로 사용 못함 -> 메모리 엄청 잡아먹음.

- 스레드 기아
    > 스레드가 잠금을 기다리다가 처리가 안되고 pending 상태가 되면 status가 처리가 안돼 실패할 가능성이 높아진다.

- CPU 혹은 요청 기아
    > 서버가 더이상 처리를 못하고 있다는 것을 탐지하면 CPU 기아 현상으로 서버 충돌 발생 혹은</br>원격에서 발생하고 있는 요청 큐를 통해 처리 되는 경우에만 기아가 발생한다.

- RPC 시간 초과
    > 서버 과부하가 발생하면 클라이언트에 대한 RPC응답이 늦어져서 시간초과 발생 후 재시도가 반복되어 과부화가 발생한다.

### 메모리 자원이 부족한 경우
    실행중인 요청은 res, req, rpc 객체등을 할당하기 위해 더 많은 램을 사용한다.
    메모리 기아 같은 경우 다음 상황에 발생한다.

- 테스크 종료
  - 컨테이너 관리자 - 가용한 자원의 한계 혹은 Application의 특정한 충독도 테스트 강제종료

- 자바 가비지 컬렉션 수행률 증가로 인한 CPU 사용 증가
  - 가비지 컬렉션 비정상적 작동 -> CPU 자원 사망 -> 요청 처리 속도 하락, 램 사용량 증가 -> 가비지 컬렉션 빈번 호출 -> CPU 자원이 모자름
  > 위와 같은 상황을 죽음의 GC 소용돌이라고 부른다.

- 캐시 활용률의 감소
  - 가용한 RAM 부족 -> Application 수준 캐시 활용률 감소 -> 더 많은 RPC 요청 -> 과부하

### 스레드
    직접적으로 에러를 발생 시키거나 혹은 건강 상태 점검의 실패를 야기
    서버가 필요 한다고 스레드 생성 시 많은 RAM을 소비한다.
    > 극단적인 경우 스레드 ID가 소진된다.

### 파일 서술자
    파일 서술자가 부족해지면 네트워크 연결의 초기화가 불가능 해져서 건강상태 점검이 실패한다.

### 자원간 의존성
    자원의 부족은 또 다른 자원에 영향을 미쳐, 다른 요소의 자원 부족이 고통받고 있는 서비스가 근본 원인 처럼 보여 디버깅이 더 어렵다.

### 서비스 이용 불가
    자원의 부족은 서버의 충돌을 야기한다.
    > ex) 서버 메모리 과할당 -> 충돌 발생 -> 나머지 서버의 과부하 발생 및 충돌 -> 서버 다운 -> 재시작 할 밀린 요청 감당 X

## 서버 과부하 방지 전략
1. 서버 수용량 한계에 대해 부하 테스트 및 과부하 상태에서의 실패에 대한 테스트
    + 과부하를 방지하기 위해 반드시 수행 해야하고 중요한 사항이다.
    > 실제 환경에서 테스트를 해선 안됀다. 정확히 어떤 자원이 부족했는지, 영향 예측이 어렵다.

2. 경감된 응답 제공하기
    > 품질은 낮지만 더 수원하게 연산한 결과를 사용자에게 제공

3. 과부하 상태에서 요청을 거부하는 서비스 만들기
    > 과부하가 발생하면 최대한 빠르면서 비용이 적게드는 방법으로 실패 처리

4. 고수준의 시스템들이 서버에 과부하를 유발하지 않고 요청을 거부하도록 구현하기
    - 비울에 제한을 둔다고 해서 전체적인 서비스 건광관리를 할 수는 없다.
    - 비율의 제한은 다음과 같이 구현해야만 한다.
        - 리버스 프록시
            - IP 주소 같은 것으로 양을 제한, Dos와 같은 공격을 최소화
        - 로드밸런서
            - 시스템 상태가 과부하인 경우 스스로 요청을 차단한다. 차단 요청 비율은 서비스의 복잡도 및 밸런서가 보내오는 요청의 변화에 의해 갑작스럽게 많은 요청이 오지 않도록 제한한다.

## 수용량 계획을 실행하기
    수용량 계획은 연속적 장애를 줄일 수 있다, 어느 수준에서 장애가 발생하는지 판단 하기 위해 성능 테스트와 병행한다.

### 큐 관리하기
    큐가 가득차면 서버는 새로운 요청을 거부하게 되는데 만일 어떤 Task의 요청줄과 지연응답의 수준이 일정하면
    요청을 큐에 적재할 필요 없이 일정 수의 스레드를 점유하면 되지만 결국에 포화상태가 된다.

### 부하 제한과 적절한 퇴보
    서버가 과부하 상태에 도달하게 되면 부하 제한을 통해 유입되는 트래픽을 감소시켜 어느정도 부하를 덜어낼 수 있다.
그 목적은 서버에 메모리 부족, 건강 상태 점검 실패, 지연 시간 응답 극단적 증가 및 기타 과부화를 방지하여 서버가 계속 자신의 직업을 할 수 있게 유지 한다.

#### 적절한 퇴보는 실행 해야 할 작업의 양을 감소 시키는 것이다.
    서비스 부하 제한이나 적절한 퇴보를 적용할 떄면 다음과 같은 사항들을 고려해야한다.
- CPU 사용률, 큐의 길이등 지표를 활용해서 부하 제한이나 적절한 퇴보의 적용 여부를 결정할 것인가.
- 서버가 퇴보모드로 동작하게 되면 어떤 조치를 취해야 하는가?
- 부하제한이나 적절한 퇴보는 어느 계층에서 구현해야 하는가?

## 연속적 장애를 처리하기 위한 즉각적인 대처
### 자원의 추가 투입
    시스템의 가용성이 줄어들었는데 여분의 자원이 있다면 
    장애에 대한 조치로서 여분의 자원에 테스트를 추가하는 것이 가장 적절한 방법이지만
    죽음의 소용돌이 에서는 벗어날 수 없다.
### 서버의 재시작
    장애가 발생해서 더 이상 처리를 하지 못하면 재시작 하는 것이 도움이 된다.
    재시작이 필요한 경우는 다음과 같다.

- 자바 서버에서 죽음의 GC 소용돌이가 발생한 경우
- 일부 처리중인 요청들에겐 특별한 마감 기간은 없지만 자원을 소비중이여서 스레드 차단이 발생할 경우
- 서버에서 데드락이 발생한 경우

서버를 재시작 하기 전에 연속적 장애의 원인을 규명해야 한다.
단순한 부하가 다른 서버로 갈 뿐만 아니라 장애의 실제 원인이 콜드 캐시면 재시작으로 인해 연속적 장애로 더 크게 퍼져나갈 수 있다.

### 트래픽의 경감
    부하를 경감시키는 것은 큰 효과가 있다. 연속적 실수로 인해 발생 했고 이를 처리할 다른 방법이 없는 경우 유용하다. 만약 충돌이 발생 한다면 다음과 같은 절차를 따라야만 한다.

1. 이 상황을 유발하는 기본적인 원인 처리 (수용량의 추가등..)
2. 충돌이 사라질 만큼 부하 경감
3. 대부분의 서버가 양호한 상태
4. 점진적으로 서버에 부하를 늘려감

### 퇴보 모드로 돌아가기
    실행할 작업의 량을 줄이거나 중요하지 않는 트래픽을 거부하는 적절한 퇴보모드를 사용함.
> 단, 서비스 내에 구현되어야 하고 어떤 트래픽에 퇴보모드로 응답해야 할 지와 전체 Payload중 구별

#### 문제가 있는 트래픽 배제 하기
    일부 쿼리가 너무 많은 부하나 충돌을 유발한다면 이들에 대한 처리를 차단, 배제 해야함.

### 결론
    시스템에 과부하가 발생한다면 해결하기 위한 조치가 필요하다.
    완벽하게 처리하는 것 보다는 에러리턴 혹은 낮은 품질의 결과 리턴이 좋다.
    연속 장애를 피하려면 장애 발생 지점을 알아야만 하고 장애 발생 시, 시스템이 동작하는 것을 알아야만 한다.